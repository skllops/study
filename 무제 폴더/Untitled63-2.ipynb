{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFq-EkyL5NyT"
      },
      "outputs": [],
      "source": [
        "# csv 파일을 읽기 위해서 pandas를 import 함\n",
        "import pandas as pd\n",
        "\n",
        "# wine.csv 파일을 불러옴\n",
        "f = pd.read_csv(\"/content/wine.csv\")\n",
        "\n",
        "# 첫번째 행(첫번째 데이터)의 모든 컬럼 정보를 불러옴\n",
        "# iloc은 integer location으로 첫번째 인자는 첫번째 행, 두번째 인자는 전체 컬럼을 의미한다)\n",
        "print(f.iloc[0,:])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# f 데이터는 pandas Dataframe 데이터 타입이기 때문에 corr() 내장함수를 사용할 수 있다.\n",
        "# 이는 각 컬럼끼리 페어하게 correlation coefficient 값을 출력해준다.\n",
        "f.corr()"
      ],
      "metadata": {
        "id": "FuhtD9Br5eSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 바로 위 셀에서 f.corr()으로 alcohol과 상관계수가 플러스마이너스 0.25 이상인 컬럼들만 확인하고 \n",
        "# f에서 volatile acidity, residual sugar, chlorides, total sulfur dioxide, density, quality, class 만 가져온다.\n",
        "X = f[['volatile acidity','residual sugar','chlorides','total sulfur dioxide','density','quality','class']]\n",
        "\n",
        "# target 값인 alcohol 컬럼만 가져온다.\n",
        "y = f['alcohol']\n",
        "\n",
        "# X는 즉 피쳐 데이터이고, 전체 데이터에서 모델 훈련에만 쓸 4000개의 데이터만 가져온다, 그리고 컬럼 또한 모두 가져온다.\n",
        "X_train = X.iloc[:4000,:]\n",
        "# X는 즉 피쳐 데이터이고, 전체 데이터에서 모델 validation에만 쓸 4000개이외의 데이터만 가져온다, 그리고 컬럼 또한 모두 가져온다.\n",
        "X_valid = X.iloc[4000:,:]\n",
        "\n",
        "# y는 훈련에 쓸 정답값 데이터다. 이것도 똑같이 X와 매칭해서 가져와야하니까 4000개만 슬라이싱해서 가져온다, 컬럼은 1개뿐이므로 따로 인덱싱하지 않아도 된다.\n",
        "y_train = y.iloc[:4000]\n",
        "\n",
        "# y는 validation에 쓸 정답값 데이터다. \n",
        "# 이것도 똑같이 X와 매칭해서 가져와야하니까 4000개이외만 슬라이싱해서 가져온다, 컬럼은 1개뿐이므로 따로 인덱싱하지 않아도 된다.\n",
        "y_valid = y.iloc[4000:]"
      ],
      "metadata": {
        "id": "1-NkYCzv55RH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터를 제대로 슬라이싱 했는지 갯수를 확인한다. \n",
        "print(len(X_train))\n",
        "print(len(X_valid))\n",
        "print(len(y_train))\n",
        "print(len(y_valid))"
      ],
      "metadata": {
        "id": "WRwSNinP7ga4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 폴리노미얼 피쳐를 만들기 위해 sklearn의 PolynomialFeatures를 가지고옴\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "# PolynomialFeatures 함수를 통해 데이터(피처)를 n의 제곱까지의 피처를 늘릴 준비를 한다. \n",
        "# degree가 2 이고, 데이터의 컬럼이 A,B 이렇게라면 A^2, B^2, AB, A, B 이렇게 되겠다.\n",
        "poly_features = PolynomialFeatures(degree=2, include_bias=False)\n",
        "\n",
        "# X train이 가지고 있는 컬럼이 몇개인지 파악, 몇개까지의 feature를 늘려야하는지 분석함.(fit이라는 말에 속으면 안된다.)\n",
        "poly_features.fit(X_train)\n",
        "\n",
        "# X_train은 원래 7개 이지만 PolynomialFeatures 때문에 35개로 컬럼이 늘어난다. 이를 poly_X라는 새로운 X로 정의한다.\n",
        "poly_X= poly_features.transform(X_train)"
      ],
      "metadata": {
        "id": "d4hES4J36NHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sklearn에서 지원해주는 SGDRegressor를 가져온다.\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "\n",
        "# SGDRegressor 객체를 생성할건데 객체 안에 훈련 옵션을 셋팅한다. 경사하강법을 50번 반복할것이며(max_iter), loss를 언제까지 줄일건지(최대한 1e-3값 까지)\n",
        "# 이외 옵션은 구글에서 검색해서 사람들이 대표적으로 사용하는 셋팅값을 불러와서 자주 쓴다.\n",
        "sgd_reg = SGDRegressor(max_iter=50, tol=1e-3, penalty=None, eta0=0.1, random_state=42)\n",
        "\n",
        "# PolynomialFeatures를 적용한 35개 컬럼의 poly_X와 그에 대응하는 정답값인 y_train를 모델한테 주고, SGD리그레서의 w 들을 학습시킨다.\n",
        "sgd_reg.fit(poly_X, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "id": "hNN3TGbg6aP1",
        "outputId": "6bf18c5f-13ec-420f-c216-b878a0d76ed5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1548: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDRegressor(eta0=0.1, max_iter=50, penalty=None, random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SGDRegressor(eta0=0.1, max_iter=50, penalty=None, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDRegressor</label><div class=\"sk-toggleable__content\"><pre>SGDRegressor(eta0=0.1, max_iter=50, penalty=None, random_state=42)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# PolynomialFeatures는 이미 X_train의 컬럼이 몇개고, 몇개까지 늘려야하는지 분석했다, \n",
        "# 굳이 X_valid로 또 분석 시킬 필요가 없다(X_valid도 x_train이랑 피쳐 갯수가 똑같으니까)\n",
        "# 그래서 그냥 위에서 PolynomialFeatures 객체를 poly_feature로 만든걸 그대로 가져와서 fit 시키지 않고 transform만 x_valid 한테 적용하면\n",
        "# x_train과 똑같이 35개의 컬럼으로 늘어난다. 그 데이터를 X_new_poly라고 정의하는 것이다. \n",
        "\n",
        "X_new_poly = poly_features.transform(X_valid)\n",
        " "
      ],
      "metadata": {
        "id": "r4Hvom9N6oVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MSE를 가지고 예측값과 실제값의 차이를 측정할 것이다. \n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# 훈련이 완료된 sgd_reg에다가 valid set이며, PolynomialFeatures를 적용시킨 35개 컬럼의 X_new_poly를 넣고 prediction 값을 뽑아낸다. \n",
        "y_predict = sgd_reg.predict(X_new_poly)\n",
        "\n",
        "# MSE(예측값들, 실제 값들)\n",
        "print(mean_squared_error(y_predict,y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaJLsMUV6xdl",
        "outputId": "a140dcfd-cade-43c0-c9fb-d57a0a48de01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8.025251371673693e+35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G04Pw1IR747N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}